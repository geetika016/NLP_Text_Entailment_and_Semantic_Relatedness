{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOqySLsaQ4bq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#import urllib2\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "#import pydot_ng as pydot\n",
    "import graphviz\n",
    "#from ggplot import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Embedding, Dense, Input, Dropout, Reshape, BatchNormalization, TimeDistributed, Lambda, Layer, LSTM, Bidirectional, Convolution1D, GRU, add, concatenate\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard, BaseLogger, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjJLxQelQ4bt"
   },
   "outputs": [],
   "source": [
    "training_sample_size = -1 # Change this to -1 if you want all\n",
    "max_seq_length = 20 # max 400\n",
    "\n",
    "model_name = 'small'\n",
    "\n",
    "lr = 0.001\n",
    "lr_decay = 1e-4\n",
    "epochs = 30\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQCAG3eMQ4b2"
   },
   "source": [
    "## Download GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NcD8RcySMg7K",
    "outputId": "df833d44-956e-4216-ec51-de3f8cb394d6"
   },
   "outputs": [],
   "source": [
    "glove_url = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
    "embedding_dim = 300\n",
    "glove_filename = 'glove.840B.' + str(embedding_dim) + 'd.zip'\n",
    "glove_loc = join(glove_filename)\n",
    "\n",
    "if not exists(glove_loc):\n",
    "    print('Download %s' % glove_filename)\n",
    "    get_file(glove_filename, glove_url, cache_dir='.', extract=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oezA0xIkVhkY",
    "outputId": "6dba7e87-2d2e-4b70-ac67-713f447f2deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract embedding/glove.840B.300d.txt\n",
      "Embeddings size: 2196016\n"
     ]
    }
   ],
   "source": [
    "glove_filename = os.path.join(\"embedding\", 'glove.840B.300d.txt')\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "print('Extract %s' % glove_filename)\n",
    "with open(glove_filename, 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings[word] = embedding\n",
    "        \n",
    "print('Embeddings size: %d' % len(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgKm3rvR5zht"
   },
   "source": [
    "##**Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGCtPFBLSu9K"
   },
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "  data = pd.read_csv(fileName, delimiter='\\t', header = None, skiprows=1)\n",
    "  data.columns = [\"pair_ID\", \"sentence_A\", \"sentence_B\", \"relatedness_score\", \"entailment_judgment\"]\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwqeaQNJSvAw"
   },
   "outputs": [],
   "source": [
    "train = readFile('data/SICK_train.txt')\n",
    "test = readFile('data/SICK_test_annotated.txt')\n",
    "valid = readFile('data/SICK_trial.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkhhw0-CSvDm"
   },
   "outputs": [],
   "source": [
    "train_df_features = train[['sentence_A','sentence_B']]\n",
    "textsValid = valid[['sentence_A','sentence_B']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5PmY9qeSvHF"
   },
   "outputs": [],
   "source": [
    "labels = train[\"relatedness_score\"]\n",
    "\n",
    "labelsValid = valid[\"relatedness_score\"]\n",
    "\n",
    "textsTest = test[['sentence_A','sentence_B']]\n",
    "labelsTest = test[\"relatedness_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNyeNmUIXpVB"
   },
   "outputs": [],
   "source": [
    "train_sentence1 = train['sentence_A'].values.tolist()\n",
    "train_sentence2 = train['sentence_B'].values.tolist()\n",
    "\n",
    "valid_sentence1 = valid['sentence_A'].values.tolist()\n",
    "valid_sentence2 = valid['sentence_B'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoFGuW_i6TgR"
   },
   "source": [
    "## **Normalizing Target Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ahG02Lj6kzH6",
    "outputId": "cd06a083-698e-4ecc-8bed-b3d15b738cd6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "q = np.reshape(labels.values, (-1,1))\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(q)\n",
    "labels = pd.DataFrame(scaler.transform(q))\n",
    "\n",
    "w = np.reshape(labelsValid.values, (-1,1))\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler1.fit(w)\n",
    "labelsValid = pd.DataFrame(scaler1.transform(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKbmbLEqQ4ch"
   },
   "source": [
    "## Prepare Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "okCOLHqoQ4ci",
    "outputId": "15359be8-ca56-4b4b-c60f-9a49f09cb86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4500 samples.\n",
      "Found 2184 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = len(embeddings) #200000\n",
    "\n",
    "print('Found %s samples.' % len(train_sentence1))\n",
    "\n",
    "train_sentences = train_sentence1 + train_sentence2\n",
    "valid_sentences = valid_sentence1 + valid_sentence2\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words = NUM_WORDS)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "sentence1_word_sequences = tokenizer.texts_to_sequences(train_sentence1)\n",
    "sentence2_word_sequences = tokenizer.texts_to_sequences(train_sentence2)\n",
    "\n",
    "valid_sentence1_word_sequences = tokenizer.texts_to_sequences(valid_sentence1)\n",
    "valid_sentence2_word_sequences = tokenizer.texts_to_sequences(valid_sentence2)\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QuNdxm4Q4cl"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "embedding_dim = 300\n",
    "words_len = min(NUM_WORDS, len(word_index))\n",
    "# word_embedding_matrix = np.zeros((words_len + 1, embedding_dim))\n",
    "word_embedding_matrix = np.random.random((words_len + 1, embedding_dim))\n",
    "k = 0\n",
    "for word, i in word_index.items():\n",
    "    if i >= NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "        k += 1\n",
    "        \n",
    "max_word_count_text = 0\n",
    "text_count = defaultdict(int)\n",
    "for sentence in sentence1_word_sequences:\n",
    "    max_word_count_text = max(max_word_count_text, len(sentence))\n",
    "    text_count[len(sentence)] += 1\n",
    "\n",
    "max_word_count_hypo = 0\n",
    "hypo_count = defaultdict(int)\n",
    "for sentence in sentence2_word_sequences:\n",
    "    max_word_count_hypo = max(max_word_count_hypo, len(sentence))\n",
    "    hypo_count[len(sentence)] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "wgpYf-FDQ4cn",
    "outputId": "63818558-7000-451b-a3a4-259b8576cf5b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mpl_fig = plt.figure()\n",
    "ax = mpl_fig.add_subplot(111)\n",
    "\n",
    "ax.bar(range(len(text_count)), text_count.values())\n",
    "ax.bar(range(len(hypo_count)), hypo_count.values(), alpha=0.7)\n",
    "\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "UzOSxQmvQ4cq",
    "outputId": "3897c1f2-5c00-44ff-989e-078733ece324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: -1\n",
      "Found 2163\n",
      "Total: 2185\n",
      "Max word text: 28\n",
      "Max word hypothesis: 32\n"
     ]
    }
   ],
   "source": [
    "print('Null word embeddings: %d' % (np.sum(np.sum(word_embedding_matrix, axis=1) == 0) - 1))\n",
    "print('Found %d' % k)\n",
    "print('Total: %d' % len(word_embedding_matrix))\n",
    "print('Max word text: %d' % max_word_count_text)\n",
    "print('Max word hypothesis: %d' % max_word_count_hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Su4IQn5iQ4cs",
    "outputId": "b9b7c1b7-67ff-45c5-83ed-808bd939e5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sentence1 tensor: (4500, 20)\n",
      "Shape of sentence2 tensor: (4500, 20)\n",
      "Shape of label tensor: (4500, 1)\n"
     ]
    }
   ],
   "source": [
    "s1_data = pad_sequences(sentence1_word_sequences, maxlen = max_seq_length)\n",
    "s2_data = pad_sequences(sentence2_word_sequences, maxlen = max_seq_length)\n",
    "s1_dataValid = pad_sequences(valid_sentence1_word_sequences, maxlen = max_seq_length)\n",
    "s2_dataValid = pad_sequences(valid_sentence2_word_sequences, maxlen = max_seq_length)\n",
    "\n",
    "\n",
    "#labels = np_utils.to_categorical(le.fit_transform(train[\"entailment_judgment\"].values)).astype(\"int64\")\n",
    "#labelsValid = np_utils.to_categorical(le.fit_transform(valid[\"entailment_judgment\"].values)).astype(\"int64\")\n",
    "\n",
    "\n",
    "\n",
    "print('Shape of sentence1 tensor:', s1_data.shape)\n",
    "print('Shape of sentence2 tensor:', s2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "WiSmSQq7Q4cv",
    "outputId": "34bceb14-c291-4317-bd5e-bc13907efe82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample\n",
      "Text: \n",
      "A group of kids is playing in a yard and an old man is standing in the background\n",
      "Word sequence: \n",
      "[1, 63, 10, 114, 2, 12, 5, 1, 212, 6, 19, 271, 4, 2, 21, 5, 3, 213]\n",
      "Pad: \n",
      "[  0   0   1  63  10 114   2  12   5   1 212   6  19 271   4   2  21   5\n",
      "   3 213]\n"
     ]
    }
   ],
   "source": [
    "print('One sample')\n",
    "\n",
    "print('Text: ')\n",
    "print( train_sentence1[0] )\n",
    "\n",
    "print('Word sequence: ')\n",
    "print( sentence1_word_sequences[0] )\n",
    "\n",
    "print('Pad: ')\n",
    "print( s1_data[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNHgkPs2Q4cy"
   },
   "source": [
    "## Helper methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BET_Zz9xQ4cy"
   },
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def cosine_distance(y1, y2):\n",
    "    mult =  tf.multiply(y1, y2)\n",
    "    cosine_numerator = tf.reduce_sum( mult, axis = -1)\n",
    "    y1_norm = tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(y1), axis=-1 ), eps) ) \n",
    "    y2_norm = tf.sqrt(tf.maximum(tf.reduce_sum(tf.square(y2), axis=-1 ), eps) ) \n",
    "    return cosine_numerator / y1_norm / y2_norm\n",
    "\n",
    "def cal_relevancy_matrix(text_vector, hypo_vector):\n",
    "    text_vector_tmp = tf.expand_dims(text_vector, 1) # [batch_size, 1, question_len, dim]\n",
    "    hypo_vector_tmp = tf.expand_dims(hypo_vector, 2) # [batch_size, passage_len, 1, dim]\n",
    "    relevancy_matrix = cosine_distance(text_vector_tmp, hypo_vector_tmp) # [batch_size, passage_len, question_len]\n",
    "    return relevancy_matrix\n",
    "\n",
    "def mask_relevancy_matrix(relevancy_matrix, text_mask, hypo_mask):\n",
    "    relevancy_matrix = tf.multiply(relevancy_matrix, K.expand_dims(text_mask, 1))\n",
    "    relevancy_matrix = tf.multiply(relevancy_matrix, K.expand_dims(hypo_mask, 2))\n",
    "    return relevancy_matrix\n",
    "\n",
    "def max_mean_pooling(repres, cosine_matrix):\n",
    "    \n",
    "    repres.append(tf.reduce_max(cosine_matrix, axis = 2, keep_dims = True))\n",
    "    repres.append(tf.reduce_mean(cosine_matrix, axis = 2, keep_dims = True))\n",
    "\n",
    "    return repres\n",
    "\n",
    "def matching_layer(inputs):\n",
    "    forward_relevancy_matrix = cal_relevancy_matrix(inputs[0], inputs[2])\n",
    "    backward_relevancy_matrix = cal_relevancy_matrix(inputs[1], inputs[3])\n",
    "\n",
    "    representation = []\n",
    "\n",
    "    max_mean_pooling(representation, forward_relevancy_matrix)\n",
    "    max_mean_pooling(representation, backward_relevancy_matrix)\n",
    "    \n",
    "    return representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUAgat75Q4c1"
   },
   "source": [
    "## Matching layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cvU0pxoQ4c2"
   },
   "outputs": [],
   "source": [
    "class MatchLayer(Layer):\n",
    "\n",
    "    def __init__(self, dim, seq_length, **kwargs):\n",
    "        super(MatchLayer, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.dim = dim\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('`MatchLayer` layer should be called '\n",
    "                             'on a list of inputs')\n",
    "        \n",
    "        if all([shape is None for shape in input_shape]):\n",
    "            return\n",
    "        \n",
    "        super(MatchLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if not isinstance(inputs, list):\n",
    "            raise ValueError('A `MatchLayer` layer should be called ')\n",
    "        \n",
    "        return matching_layer(inputs)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if not isinstance(input_shape, list):\n",
    "            raise ValueError('A `MatchLayer` layer should be called '\n",
    "                             'on a list of inputs.')\n",
    "        \n",
    "        input_shapes = input_shape\n",
    "        output_shape = list(input_shapes[0])\n",
    "                             \n",
    "        return [ (None, output_shape[1] , 1) ] * 4 \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "\n",
    "        }\n",
    "        base_config = super(MatchLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "class MaxPoolingLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaxPoolingLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(MaxPoolingLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return max_mean_pooling([], inputs)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):            \n",
    "        output_shape = list(input_shape)\n",
    "        return [ (None, output_shape[1] , 1) ] * 2\n",
    "    \n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return [mask, mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "7CwmikhEQ4c5",
    "outputId": "2a2029de-8a8f-41f1-8261-0e0a714e82ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-56408f122e2d>:45: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Model created\n"
     ]
    }
   ],
   "source": [
    "models = {};\n",
    "\n",
    "def word_context(input, name):\n",
    "    embedding = Embedding(words_len + 1,\n",
    "                     embedding_dim,\n",
    "                     weights = [word_embedding_matrix],\n",
    "                     input_length = max_seq_length,\n",
    "                     trainable = False,\n",
    "                     name = name + '_embedding')(input)\n",
    "    \n",
    "    word = Dropout(0.1)(embedding)\n",
    "\n",
    "    context = Bidirectional(LSTM(100, return_sequences = True),\n",
    "                            merge_mode = None,\n",
    "                            name = name + '_context')(word)\n",
    "    \n",
    "    return (word, context)\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    sentence1_input = Input(shape=(max_seq_length,), dtype='int32', name = 'text')\n",
    "    sentence2_input = Input(shape=(max_seq_length,), dtype='int32', name = 'hypothesis')\n",
    "    \n",
    "    (text_embedding, text_context) = word_context(sentence1_input, 'text')\n",
    "    (hypo_embedding, hypo_context) = word_context(sentence2_input, 'hypothesis')\n",
    "\n",
    "    left_context = []\n",
    "    left_context.extend(hypo_context)\n",
    "    left_context.extend(text_context)\n",
    "    \n",
    "    left_match = MatchLayer(embedding_dim, max_seq_length)( left_context )\n",
    "    \n",
    "    right_context = []\n",
    "    right_context.extend(text_context)\n",
    "    right_context.extend(hypo_context)\n",
    "    \n",
    "    right_match = MatchLayer(embedding_dim, max_seq_length)( right_context )\n",
    "    \n",
    "    cosine_left = Lambda(lambda x_input: cal_relevancy_matrix(x_input[0], x_input[1]))( [text_embedding, hypo_embedding] )\n",
    "    cosine_right = Lambda(lambda cosine: tf.transpose(cosine, perm=[0,2,1]))( cosine_left )\n",
    "    \n",
    "    left_representation = MaxPoolingLayer()( cosine_left )\n",
    "    right_representation = MaxPoolingLayer()( cosine_right )\n",
    "    \n",
    "    left_representation.extend( left_match )\n",
    "    right_representation.extend( right_match ) \n",
    "    \n",
    "    left = concatenate(left_representation, axis = 2)\n",
    "    left = Dropout(0.1)(left)\n",
    "    \n",
    "    right = concatenate(right_representation, axis = 2)\n",
    "    right = Dropout(0.1)(right)\n",
    "    \n",
    "\n",
    "    aggregation_left = Bidirectional(LSTM(100),\n",
    "                            name = 'aggregation_text_context')(left)\n",
    "    \n",
    "    aggregation_right = Bidirectional(LSTM(100),\n",
    "                            name = 'aggregation_hypo_context')(right)\n",
    "    \n",
    "    aggregation = concatenate([aggregation_left, aggregation_right], axis = -1)\n",
    "                               \n",
    "    pred = Dense(200, activation = 'tanh', name = 'tanh_prediction')(aggregation)\n",
    "    pred = Dense(1, activation = 'sigmoid', name = 'sigmoid_prediction')(pred)\n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model = Model(inputs=[sentence1_input, sentence2_input], outputs = pred)\n",
    "    model.compile(loss = 'mean_squared_error', \n",
    "              optimizer = optimizer,\n",
    "              metrics = ['mse'])\n",
    "    \n",
    "    print('Model created')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "models['adam'] = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLrVviOrQ4c-"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "S3Ad6hIrXXb2",
    "outputId": "003b3933-3530-4e33-f7cf-7549b529a783"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start learning adam at 1585010011\n",
      "Epochs: 30\n",
      "Batch size: 64\n",
      "WARNING:tensorflow:From /Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "WARNING:tensorflow:From /Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/30\n",
      " - 25s - loss: 0.0570 - mse: 0.0570 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "WARNING:tensorflow:From /Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geetikasharma/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_mean_squared_error available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 23s - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 3/30\n",
      " - 21s - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 4/30\n",
      " - 24s - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 5/30\n",
      " - 23s - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 6/30\n",
      " - 23s - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 7/30\n",
      " - 21s - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 8/30\n",
      " - 27s - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 9/30\n",
      " - 29s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 10/30\n",
      " - 22s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 11/30\n",
      " - 23s - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 12/30\n",
      " - 28s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 13/30\n",
      " - 23s - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 14/30\n",
      " - 23s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 15/30\n",
      " - 23s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 16/30\n",
      " - 25s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 17/30\n",
      " - 23s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 18/30\n",
      " - 23s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 19/30\n",
      " - 23s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 20/30\n",
      " - 24s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 21/30\n",
      " - 23s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 22/30\n",
      " - 23s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 23/30\n",
      " - 24s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 24/30\n",
      " - 29s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 25/30\n",
      " - 27s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 26/30\n",
      " - 22s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 27/30\n",
      " - 23s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 28/30\n",
      " - 25s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 29/30\n",
      " - 24s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 30/30\n",
      " - 24s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Time: 729\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    callbacks = [\n",
    "        BaseLogger(),\n",
    "        ReduceLROnPlateau(monitor = 'val_loss', factor=0.2, patience=5, min_lr=0.001),\n",
    "        TensorBoard(log_dir='./' + model_name + '-' + name + '-logs', histogram_freq=0, write_graph=True, write_images=True),\n",
    "        ModelCheckpoint(model_name + '-' + name + '-checkpoint-weights.{epoch:02d}.hdf5', monitor='val_mean_squared_error', save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('')\n",
    "    print('Start learning %s at %d' % (name, start_time))\n",
    "    print('Epochs: %d' % epochs)\n",
    "    print('Batch size: %d' % batch_size)\n",
    "\n",
    "    history = model.fit([s1_data, s2_data],\n",
    "                        labels,\n",
    "                        epochs = 30,\n",
    "                        batch_size = batch_size,\n",
    "                        validation_data=([s1_dataValid, s2_dataValid], labelsValid),\n",
    "                        shuffle = True, #True,\n",
    "                        verbose = 2,\n",
    "                        callbacks = callbacks)\n",
    "\n",
    "    model.save(model_name + '-' + name + '-model.h5')\n",
    "    model.save_weights(model_name + '-' + name + '-weights.h5')\n",
    "\n",
    "    end_time = time.time()\n",
    "    average_time_per_epoch = (end_time - start_time) / epochs\n",
    "    results.append((history, average_time_per_epoch))\n",
    "    \n",
    "    print('Time: %d' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49C1lal7Q4dM"
   },
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "89ZtyaoaQ4dO",
    "outputId": "394df9bb-faf7-4151-f8c5-b641647ad82f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test sentence1 tensor: (4927, 20)\n",
      "Shape of test sentence2 tensor: (4927, 20)\n",
      "Shape of test label tensor: (4927,)\n"
     ]
    }
   ],
   "source": [
    "test_s1_word_sequences = tokenizer.texts_to_sequences(test['sentence_A'].values.tolist())\n",
    "test_s2_word_sequences = tokenizer.texts_to_sequences(test['sentence_B'].values.tolist())\n",
    "\n",
    "test_s1_data = pad_sequences(test_s1_word_sequences, maxlen = max_seq_length)\n",
    "test_s2_data = pad_sequences(test_s2_word_sequences, maxlen = max_seq_length)\n",
    "test_labels = test[\"relatedness_score\"]\n",
    "\n",
    "print('Shape of test sentence1 tensor:', test_s1_data.shape)\n",
    "print('Shape of test sentence2 tensor:', test_s2_data.shape)\n",
    "print('Shape of test label tensor:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvOxfHsxm_9l"
   },
   "outputs": [],
   "source": [
    "e = np.reshape(test_labels.values, (-1,1))\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler1.fit(e)\n",
    "test_labels = pd.DataFrame(scaler1.transform(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vRsPG2Usex5s",
    "outputId": "ac70e4c9-e8ba-4d2b-935e-5eaff18369c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model adam\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print('')\n",
    "    print('Model %s' % name)\n",
    "    test_pred = model.predict([test_s1_data, test_s2_data], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfhSXjw1Q4dh"
   },
   "outputs": [],
   "source": [
    "output= list()\n",
    "for x in test_pred:\n",
    "  output.append(x[0])\n",
    "\n",
    "test[\"Actual Output\"] = output\n",
    "test[\"normalized label\"] = labelsTest\n",
    "test.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p9eMqLMPQ4dj",
    "outputId": "60554ce5-bbfa-4e6a-bfaa-964d352041d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6788329437071638"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.corrcoef(test['normalized label'], test['Actual Output'])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MWdTvxStQ4dm",
    "outputId": "50ffe926-c6c0-4a9e-bdcf-15d023040089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.609\n"
     ]
    }
   ],
   "source": [
    "# calculate the spearman's correlation between two variables\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "from scipy.stats import spearmanr\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(test['normalized label'], test['Actual Output'])\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TI9T6x_Q1UKr"
   },
   "outputs": [],
   "source": [
    "output = np.reshape(test['Actual Output'].values, (-1,1))\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "scaler.fit(output)\n",
    "output = pd.DataFrame(scaler.transform(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "id": "VNcp2aP3pZ2L",
    "outputId": "8be06592-f2c2-4abe-a1a9-171fab1e8a2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.583170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.177167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.032782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.259556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.252651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>2.871939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>3.351052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>1.227269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>2.161908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>1.869100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4927 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     2.583170\n",
       "1     4.177167\n",
       "2     3.032782\n",
       "3     3.259556\n",
       "4     3.252651\n",
       "...        ...\n",
       "4922  2.871939\n",
       "4923  3.351052\n",
       "4924  1.227269\n",
       "4925  2.161908\n",
       "4926  1.869100\n",
       "\n",
       "[4927 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Semantic_Relatedness_Final.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
